
trainer:
  checkpoint_callback: true
  callbacks:
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
      init_args:
        logging_interval: epoch
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        save_top_k: 1
        monitor: val_acc
        mode: max
        filename: 'VitB16-{epoch}-{step}-{val_acc:.4f}'
  gpus: 0, 1
  accelerator: ddp
  check_val_every_n_epoch: 1
  max_epochs: 10

model:
  model_name: 'vit_base_patch16_224'
  # training
  optimizer_name: 'adam'
  scheduler_name: 'warmup_cosine'
  learning_rate: 5e-5
  weight_decay: 0
  smoothing: 0.1
  pretrained: True
data:
  data_adr: '../data'
  train_batch_size: 16
  eval_batch_size: 16
  num_workers: 4
  img_size: 224
